"""
This script is used to refactor the ffi skeleton code.

The ffi skeleton code is generated by the following command:

```
python apps/refactor_ffi.py folder_path --refactor --inplace
```

The refactored code is saved in the same folder.
"""
import os
import re
import argparse
from collections import namedtuple
from typing import List, Dict, Set, Tuple, Optional

"""
Entry to store the information of the function registration to be extracted from the file

- lineno_begin: the line number of the first line of the function registration
- lineno_end: the line number of the last line of the function registration
- method: the method of the function registration, can be packed, typed, method
- name: the name of the function registration
- function: the function body of the function registration
"""
Entry = namedtuple("Entry", ["lineno_begin", "lineno_end", "method", "name", "function"])


def is_in_string_or_comment(text: str, pos: int) -> bool:
    """Check if position is inside a string literal or comment"""
    # Simple heuristic: check if we're in a string or comment
    before = text[:pos]

    # Count quotes to see if we're in a string
    single_quotes = before.count("'") - before.count("\\'")
    double_quotes = before.count('"') - before.count('\\"')

    # If odd number of quotes, we're inside a string
    if single_quotes % 2 == 1 or double_quotes % 2 == 1:
        return True

    # Check for line comments
    line_start = before.rfind('\n')
    if line_start == -1:
        line_start = 0
    else:
        line_start += 1

    current_line = text[line_start:pos]
    if '//' in current_line:
        comment_pos = current_line.find('//')
        if comment_pos < pos - line_start:
            return True

    # Check for block comments (simplified)
    block_comment_start = before.rfind('/*')
    block_comment_end = before.rfind('*/')
    if block_comment_start != -1 and (block_comment_end == -1 or block_comment_start > block_comment_end):
        return True

    return False


def find_matching_paren(text: str, start_pos: int) -> int:
    """Find the matching closing parenthesis, accounting for nested parens"""
    paren_count = 0
    i = start_pos

    while i < len(text):
        if not is_in_string_or_comment(text, i):
            if text[i] == '(':
                paren_count += 1
            elif text[i] == ')':
                paren_count -= 1
                if paren_count == 0:
                    return i
        i += 1

    return -1


def extract_function_name(text: str, start_pos: int) -> str:
    """Extract function name from TVM_FFI_REGISTER_GLOBAL("name")"""
    # Find the opening parenthesis
    paren_start = text.find('(', start_pos)
    if paren_start == -1:
        return ""

    # Find the closing parenthesis
    paren_end = find_matching_paren(text, paren_start)
    if paren_end == -1:
        return ""

    # Extract content between parentheses
    content = text[paren_start + 1:paren_end].strip()

    # Remove quotes
    if content.startswith('"') and content.endswith('"'):
        content = content[1:-1]
    elif content.startswith("'") and content.endswith("'"):
        content = content[1:-1]

    return content


def extract_method_and_function(text: str, start_pos: int) -> Tuple[str, str]:
    """Extract method type and function body from set_body* call"""
    # Find the method type
    method_match = re.search(r'\.set_body(_typed|_method|_packed)?', text[start_pos:])
    if not method_match:
        return "", ""

    method_type = method_match.group(1)
    if method_type == "_packed":
        method_type = "packed"
    elif method_type == "_typed":
        method_type = "typed"
    elif method_type == "_method":
        method_type = "method"
    else:
        method_type = "packed"  # default

    # Find the function body
    method_pos = start_pos + method_match.start()
    paren_start = text.find('(', method_pos)
    if paren_start == -1:
        return method_type, ""

    paren_end = find_matching_paren(text, paren_start)
    if paren_end == -1:
        return method_type, ""

    function_body = text[paren_start + 1:paren_end].strip()
    return method_type, function_body


def extract_registration_entries(lines: List[str]) -> List[Entry]:
    """
    Extract the registration entries from the file

    Parameters
    ----------
    lines: list[str]
        The lines of the file

    Returns
    -------
    entries: list[Entry]
        The list of registration entries
    """
    entries = []
    full_text = '\n'.join(lines)

    # Find all TVM_FFI_REGISTER_GLOBAL occurrences
    pattern = r'TVM_FFI_REGISTER_GLOBAL\s*\('
    matches = list(re.finditer(pattern, full_text))

    for match in matches:
        start_pos = match.start()

        # Find the line number of the start
        text_before = full_text[:start_pos]
        lineno_begin = text_before.count('\n')

        # Extract function name
        name = extract_function_name(full_text, start_pos)
        if not name:
            continue

        # Find the end of the registration (look for the closing semicolon)
        # We need to find the complete statement including the method call
        search_start = match.end()

        # Find the method call and function body
        method_match = re.search(r'\.set_body(_typed|_method|_packed)?', full_text[search_start:])
        if not method_match:
            continue

        method_pos = search_start + method_match.start()
        paren_start = full_text.find('(', method_pos)
        if paren_start == -1:
            continue

        paren_end = find_matching_paren(full_text, paren_start)
        if paren_end == -1:
            continue

        function_body = full_text[paren_start + 1:paren_end].strip()

        # Determine method type
        method_type = method_match.group(1)
        if method_type == "_packed":
            method_type = "packed"
        elif method_type == "_typed":
            method_type = "typed"
        elif method_type == "_method":
            method_type = "method"
        else:
            method_type = "packed"  # default

        # Find the semicolon that comes after the function body
        semicolon_pos = full_text.find(';', paren_end)
        if semicolon_pos == -1:
            continue

        # Find the line number of the end (the line containing the semicolon)
        text_to_end = full_text[:semicolon_pos]
        lineno_end = text_to_end.count('\n') + 1

        entries.append(Entry(
            lineno_begin=lineno_begin,
            lineno_end=lineno_end,
            method=method_type,
            name=name,
            function=function_body
        ))

    return entries


def print_entries(entries: List[Entry]) -> None:
    """
    Print the registration entries to the screen in the following example

    ```
    file_name.cc [lineno_begin:lineno_end): name=<name>, method=<method>
    ====================================================================
    <function>
    ...
    ```
    """
    for entry in entries:
        print(f"[{entry.lineno_begin}:{entry.lineno_end}): name={entry.name}, method={entry.method}")
        print("=" * 70)
        print(entry.function)
        print()


def update_insert_task_with_include_reflection_h(lines: List[str], insert_task: Dict[int, str]) -> None:
    """
    Detect if the file already include tvm/ffi/reflection/reflection.h
    if not, add an include to it, follow google c style
    if it does, do not add it again
    make sure to add the include after the initial ASF header
    """
    # Check if reflection.h is already included
    for line in lines:
        if 'tvm/ffi/reflection/reflection.h' in line:
            return

    # Find where to insert the include
    insert_line = 0
    in_header = True

    for i, line in enumerate(lines):
        stripped = line.strip()

        # Skip ASF header and initial comments
        if in_header:
            if stripped.startswith('//') or stripped.startswith('/*') or stripped.startswith('*') or stripped == '':
                continue
            else:
                in_header = False

        # Find the position after existing includes
        if stripped.startswith('#include'):
            insert_line = i + 1
        elif stripped.startswith('#include') == False and insert_line > 0:
            break

    # Add the include without extra newline
    include_line = '#include <tvm/ffi/reflection/reflection.h>'
    insert_task[insert_line] = include_line


def group_consecutive_entries(entries: List[Entry], lines: List[str]) -> List[List[Entry]]:
    """Group consecutive entries that should be combined into single blocks"""
    if not entries:
        return []

    # Sort entries by line number first
    sorted_entries = sorted(entries, key=lambda e: e.lineno_begin)

    groups = []
    current_group = [sorted_entries[0]]

    for i in range(1, len(sorted_entries)):
        prev_entry = sorted_entries[i-1]
        curr_entry = sorted_entries[i]

        # Check if there are only whitespace lines between entries
        # Start from the line AFTER the previous entry ends
        has_only_whitespace = True
        for line_idx in range(prev_entry.lineno_end + 1, curr_entry.lineno_begin):
            if line_idx < len(lines):
                line_content = lines[line_idx].strip()
                if line_content:
                    has_only_whitespace = False
                    break

        if has_only_whitespace:
            current_group.append(curr_entry)
        else:
            groups.append(current_group)
            current_group = [curr_entry]

    groups.append(current_group)
    return groups


def generate_ffi_block(group: List[Entry]) -> str:
    """Generate the TVM_FFI_STATIC_INIT_BLOCK for a group of entries"""
    lines = []
    lines.append("TVM_FFI_STATIC_INIT_BLOCK({")
    lines.append("  namespace refl = tvm::ffi::reflection;")

    # Start the GlobalDef chain
    first_entry = group[0]
    if first_entry.method == "packed":
        method_name = "def_packed"
    elif first_entry.method == "typed":
        method_name = "def"
    elif first_entry.method == "method":
        method_name = "def_method"
    else:
        method_name = "def"  # default for set_body

    lines.append(f'  refl::GlobalDef()')
    lines.append(f'    .{method_name}("{first_entry.name}", {first_entry.function})')

    # Add subsequent entries
    for entry in group[1:-1]:  # All except the last one
        if entry.method == "packed":
            method_name = "def_packed"
        elif entry.method == "typed":
            method_name = "def"
        elif entry.method == "method":
            method_name = "def_method"
        else:
            method_name = "def"  # default for set_body

        lines.append(f'    .{method_name}("{entry.name}", {entry.function})')

    # Handle the last entry specially (add semicolon on same line)
    if len(group) > 1:
        last_entry = group[-1]
        if last_entry.method == "packed":
            method_name = "def_packed"
        elif last_entry.method == "typed":
            method_name = "def"
        elif last_entry.method == "method":
            method_name = "def_method"
        else:
            method_name = "def"  # default for set_body

        lines.append(f'    .{method_name}("{last_entry.name}", {last_entry.function});')
    else:
        # If there's only one entry, add semicolon to the first (and only) entry
        lines[-1] = lines[-1] + ';'

    lines.append("});")

    return '\n'.join(lines)


def print_diff(original_lines: List[str], delete_task: Set[int], insert_task: Dict[int, str]) -> None:
    """
    Print out the diff line indicated by the delete_task (look up original lines)
    insert_task simply just print out the new lines, in both cases, print out the line number range

    Parameters
    ----------
    original_lines: list[str]
        The original lines of the file
    delete_task: set[int]
        Line numbers to delete
    insert_task: dict[int, str]
        Line numbers and content to insert
    """
    print("=== DIFF ===")

    # Combine all operations and sort by line number
    all_operations = []

    # Add delete operations
    if delete_task:
        delete_ranges = []
        sorted_deletes = sorted(delete_task)
        start = sorted_deletes[0]
        end = sorted_deletes[0]

        for line_no in sorted_deletes[1:]:
            if line_no == end + 1:
                end = line_no
            else:
                delete_ranges.append((start, end))
                start = line_no
                end = line_no
        delete_ranges.append((start, end))

        for start, end in delete_ranges:
            all_operations.append(('delete', start, end, None))

    # Add insert operations
    if insert_task:
        for line_no, content in insert_task.items():
            all_operations.append(('insert', line_no, line_no, content))

    # Sort all operations by line number
    all_operations.sort(key=lambda x: x[1])

    # Print operations in order
    for op_type, start, end, content in all_operations:
        if op_type == 'delete':
            print(f"DELETE lines {start+1}-{end+1}:")
            for i in range(start, end + 1):
                if i < len(original_lines):
                    print(f"  - {original_lines[i]}")
            print()
        else:  # insert
            lines_to_insert = content.split('\n')
            if lines_to_insert and lines_to_insert[-1] == '':
                lines_to_insert = lines_to_insert[:-1]

            print(f"INSERT at line {start+1}:")
            for line in lines_to_insert:
                print(f"  + {line}")
            print()


def refactor_file_content(lines: List[str], entries: List[Entry]) -> str:
    """
    Refactor the file content for given entries information

    Parameters
    ----------
    lines: list[str]
        The lines of the file

    entries: list[Entry]
        The list of registration entries

    Returns
    -------
    content: str
        The refactored content of the file
    """
    assert len(entries) > 0, "No entries to refactor"

    delete_task: Set[int] = set()
    insert_task: Dict[int, str] = {}

    # Group consecutive entries
    groups = group_consecutive_entries(entries, lines)

    # Process each group
    for group in groups:
        # Mark lines for deletion
        start_line = group[0].lineno_begin
        end_line = group[-1].lineno_end

        # Delete all lines from first entry to last entry
        for entry in group:
            delete_task.update(range(entry.lineno_begin, entry.lineno_end))

        # Also delete whitespace lines between entries in the group
        if len(group) > 1:
            for i in range(len(group) - 1):
                curr_end = group[i].lineno_end
                next_start = group[i + 1].lineno_begin
                for line_idx in range(curr_end, next_start):
                    if line_idx < len(lines) and not lines[line_idx].strip():
                        delete_task.add(line_idx)

        # Generate replacement block
        replacement = generate_ffi_block(group)
        insert_task[start_line] = replacement

    # Add include if needed
    update_insert_task_with_include_reflection_h(lines, insert_task)

    # Print diff
    print_diff(lines, delete_task, insert_task)

    # Generate output
    output_lines = []
    for i, line in enumerate(lines):
        # First, check if we need to insert content at this line
        if i in insert_task:
            output_lines.append(insert_task[i])

        # Then, check if we should keep the original line
        if i not in delete_task:
            output_lines.append(line)

    return '\n'.join(output_lines)


def process_file(filepath: str, args) -> None:
    """Process a single file"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            content = f.read()

        lines = content.split('\n')
        entries = extract_registration_entries(lines)

        if not entries:
            print(f"No TVM_FFI_REGISTER_GLOBAL found in {filepath}")
            return

        print(f"Found {len(entries)} entries in {filepath}")
        print_entries(entries)

        # Refactor the content
        new_content = refactor_file_content(lines, entries)

        if args.inplace:
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(new_content)
            print(f"Refactored {filepath}")

    except Exception as e:
        print(f"Error processing {filepath}: {e}")


def main():
    """
    Main function to run the refactor, use argparse
    """
    parser = argparse.ArgumentParser(description='Refactor TVM FFI registration patterns')
    parser.add_argument('path', help='File or directory path to refactor')
    parser.add_argument('--refactor', action='store_true', help='Perform refactoring')
    parser.add_argument('--inplace', action='store_true', help='Modify files in place')

    args = parser.parse_args()

    if not args.refactor:
        print("Use --refactor flag to perform refactoring")
        return

    if os.path.isfile(args.path):
        if args.path.endswith(('.cc', '.cpp', '.cu', '.mm')):
            process_file(args.path, args)
        else:
            print(f"Skipping non-C++/CUDA/Objective-C++ file: {args.path}")
    elif os.path.isdir(args.path):
        for root, dirs, files in os.walk(args.path):
            for file in files:
                if file.endswith(('.cc', '.cpp', '.cu', '.mm')):
                    filepath = os.path.join(root, file)
                    process_file(filepath, args)
    else:
        print(f"Path not found: {args.path}")


if __name__ == "__main__":
    main()
